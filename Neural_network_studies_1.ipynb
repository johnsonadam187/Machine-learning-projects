{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network studies 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPPLCXShStlq"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsAWWainFzej"
      },
      "source": [
        "A good dataset is the MNIST hand written numbers dataset. It is built in to sklearn and keras. Its a dataset of 60,000 images, greyscale, 28 x 28 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL70MUlbFxyP"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHzcU4ziG0cn"
      },
      "source": [
        "mnist = keras.datasets.mnist #import data\r\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data() #load the data\r\n",
        "# interestingly this load_data function returns 2 tuples of training and testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsjVTVcNHtK0"
      },
      "source": [
        "Examine the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X27zxoPLHf4P",
        "outputId": "9dc8d3cf-82da-4183-f7f5-579fb81a736e"
      },
      "source": [
        "print(f\"x_train.shape({x_train.shape}), y_train.shape({y_train.shape})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape((60000, 28, 28)), y_train.shape((60000,))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhzvKrw1ITI1"
      },
      "source": [
        "So luckily for us the data is in 60,000 28 x 28p arrays. So at the moment data cleaning/transposing is minimal. Next we can visualise an image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "oxUxD-pQH_Iu",
        "outputId": "75e203e7-cdb5-4ab6-e599-5347f6db8b93"
      },
      "source": [
        "plt.imshow(x_train[5000], cmap='gray', vmin=0, vmax=255)\r\n",
        "plt.title(f\"Image label:{y_train[5000]}\")\r\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goOtZBQrSsyq"
      },
      "source": [
        "Now lets examine the actual values within the images, to see our range of data values. If we use a pixel in the above example, we can examine the data and should see a value 0-255, as we are expecting greyscale images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6HtYDWWIC0H",
        "outputId": "838e439e-89e5-4fdf-c835-e423367f007a"
      },
      "source": [
        "x_train[5000, 9, 10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkC9fRvFTOH3"
      },
      "source": [
        "Now because we want values in between -1 and 1 for input into the neural net, we must scale the datasets, for testing and training. This is relatively simple because we only have int values in between 0 and 255, so we can divide all by 255, and we will end up with the scaled data as floating point numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qZ7T2y0TMgO"
      },
      "source": [
        "x_train = x_train/255\r\n",
        "y_train = y_train/255\r\n",
        "x_test = x_test/255\r\n",
        "y_test = y_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpBoswg1VzOk"
      },
      "source": [
        "Now we have to hink about how we build the neural network. Usually we have a Sequential network, but we have to think about how many hidden layers we have and what activation function we use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sSgAWd-VBlz"
      },
      "source": [
        "model = keras.Sequential([keras.layers.Flatten(input_shape = (28, 28)), \r\n",
        "                          keras.layers.Dense(128, activation='relu'), \r\n",
        "                          keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKKJJVrYW3O7"
      },
      "source": [
        "So here we have created a Sequential network, basically we enter in a list of all the layers, each of which has its own paramters like activation function, and number of neurons. Usually when we think of the input layer, it should be at least 1 neuron per pixel/possible value. In this instance there is a pre-made Flatten() function for images which takes in the input shape and flattens it to a 1D array. So here 28 x 28, flattened equates to 784 input neurons. We also have to think about how to construct the output layer. If we have 10 possible categories to classify between, we need 10 output neurons. The other factors like number of hidden layers/neurons, and types of activation functions can be changed according to necessity, or can be tuned like hyper-paramters.\r\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wk6oZSfegjQ"
      },
      "source": [
        "Next we .compile() the model, passing instructions on optimisation, loss/error function types, and the resultant metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7S8yx43Wvnd"
      },
      "source": [
        "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", \r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj7uDSlDeeGr"
      },
      "source": [
        "This .compile() step informs the system how we want the network to be optimised. The effectiveness of a neural network is judged on the ouput of the loss function. There are different loss functions for different analyses. The most common one is RMSE for regression analyses. RMSE measures the sum of distance of the data points from the line of best fits, and so this is a good loss function for linear regression. The optimizer is the mathematical method used to evaluate to direction of change of the loss function. Gradient descent is the original otimisation technique, to search for a global minimum in loss function value. So the way we specify these parameters in our model.compile() is important and based on the specific type of model we are looking to create. Currently 'adam' is the standard optimiser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gu_6TbWkn7L",
        "outputId": "672f871a-55c8-49ac-edb8-ca73d9813e08"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0264 - accuracy: 0.0987\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 2.8373e-06 - accuracy: 0.0975\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 5.1187e-07 - accuracy: 0.0986\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.3343e-07 - accuracy: 0.0986\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 6.3507e-08 - accuracy: 0.0994\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5487e-08 - accuracy: 0.0989\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 8.1598e-09 - accuracy: 0.0977\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 3.1388e-09 - accuracy: 0.0995\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 1.5291e-09 - accuracy: 0.0983\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 6.3175e-10 - accuracy: 0.0976\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f75b0320748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB6r_PxFuMJY"
      },
      "source": [
        "So now we train the model, we can specify number of epochs, which means the amount of times we run the training data. Next we .evaluate() the model with the testing data. The evaluate function returns loss and accuracy data for the model on the testing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4Wyf1dctsj5",
        "outputId": "e888cea8-3d49-4e3e-c31e-fbf6b9a838b9"
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, verbose=1)\r\n",
        "print(f\"Model Loss:{loss}. Model accuracy: {acc}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 1ms/step - loss: 1.2159e-09 - accuracy: 0.0980\n",
            "Model Loss:1.2159325768479334e-09. Model accuracy: 0.09799999743700027%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQN9W5FxwG_p"
      },
      "source": [
        "Currently this model is not doing very well. So we can tweak the hyper-paramters and see manually if that changes anything. We will change the model, layers, optimiser and number of epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFwRJVhPvM-H"
      },
      "source": [
        "model2 = model = keras.Sequential([keras.layers.Flatten(input_shape = (28, 28)), \r\n",
        "                          keras.layers.Dense(128, activation='sigmoid'),\r\n",
        "                          keras.layers.Dense(128, activation='sigmoid'), \r\n",
        "                          keras.layers.Dense(10, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVGj5kXw-n8"
      },
      "source": [
        "model2.compile(optimizer='SGD', loss=\"mean_absolute_error\", \r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss3HzPtlyRLA"
      },
      "source": [
        "Here we have added an extra hidden layer, and changed the activation functions to sigmoid. We also changed the optimiser to SGD (gradient descent) and specified a multi categorical loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQakBPgRxGH5",
        "outputId": "d1344c81-5ef1-43e5-c326-e2dfe7f1fd66"
      },
      "source": [
        "model2.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.0998\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.0997\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.0965\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.1001\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.0988\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.0994\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.1015\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.0986\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1139 - accuracy: 0.1007\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1140 - accuracy: 0.0992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f754e7a65c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NArvnvsM0gDV"
      },
      "source": [
        "Still not great. Convolutional Neural networks have been shown to be more effective with image data. Lets look at another model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlHJ4swvy3VK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "9PgPe7Vr0xeY",
        "outputId": "1afc155e-ac6c-42f4-845d-776ff587f6de"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-97e0a0233aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model3.compile(optimizer='SGD', loss=\"mean_absolute_error\", \n\u001b[1;32m      2\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:239 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_4 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (32, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCRmsvPc1thX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}